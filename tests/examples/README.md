# Example Parquet Files for every-eval-ever

This directory contains example parquet files generated by the optimized HELM processor to demonstrate the structure and format of files that get uploaded to HuggingFace datasets.

## File Structure

### Local Processing Files (examples)
- `chunk_0001.parquet` - Local processing file for chunk 1
- `chunk_0002.parquet` - Local processing file for chunk 2

### HuggingFace Upload Names
When uploaded, these files become:
- `data-00001.parquet` - Uploaded version of chunk_0001.parquet
- `data-00002.parquet` - Uploaded version of chunk_0002.parquet

## File Content

Each parquet file contains evaluation data with the following schema:

### Metadata Columns (added for cronjob tracking)
- `source`: Source system (e.g., "helm")
- `benchmark`: Benchmark name (e.g., "lite", "mmlu", "classic")  
- `timestamp`: Processing timestamp in UTC
- `processing_date`: Date of processing (YYYY-MM-DD)

### Evaluation Data Columns
- `evaluation_id`: Unique identifier for the evaluation
- `dataset_name`: Name of the dataset (e.g., "openbookqa")
- `hf_split`: HuggingFace dataset split (e.g., "test", "validation")
- `hf_index`: Index within the split
- `raw_input`: Original input to the model
- `ground_truth`: Expected/correct answer
- `model_name`: Name of the model (e.g., "01-ai/yi-34b")
- `model_family`: Model family/organization
- `output`: Model's output/prediction
- `evaluation_method_name`: Method used for evaluation
- `evaluation_score`: Numerical score (0.0 to 1.0 for accuracy)

## Example Statistics

From the sample files generated:

### chunk_0001.parquet (1,500 entries)
- **Models**: 01-ai/yi-34b (92.0% avg), 01-ai/yi-6b (80.0% avg), AlephAlpha/luminous-base (28.6% avg)
- **Dataset**: openbookqa
- **Size**: 134.9 KB

### chunk_0002.parquet (1,000 entries)
- **Models**: AlephAlpha/luminous-extended (27.2% avg), anthropic/claude-v1.3 (90.8% avg)
- **Dataset**: openbookqa  
- **Size**: 98.9 KB

### Comprehensive Statistics Files

The following files show the comprehensive statistics that are generated and uploaded to the scores repository using smart indexing:

- `comprehensive_stats_2025-09-04.parquet` - Per-model-per-benchmark-per-dataset statistics (example)
- `comprehensive_stats_from_chunks_2025-09-04.parquet` - Statistics generated from actual chunk data (example)
- `comprehensive_stats_helm_20250904_121834.parquet` - Earlier example of comprehensive statistics (example)

**Upload Pattern to Scores Repository:**
When uploaded to `evaleval/every_eval_score_ever`, files follow the pattern:
- `helm-00001.parquet` - Comprehensive stats for HELM source (first upload)
- `helm-00002.parquet` - Comprehensive stats for HELM source (second upload)
- `eval_harness-00001.parquet` - Comprehensive stats for eval-harness source (first upload)
- `all-00001.parquet` - Comprehensive stats for all sources combined (when processing all)

Each comprehensive stats file contains **one row per model-benchmark-dataset combination** with full statistical measures including:
- `accuracy`, `mean_score`, `std_score`
- Quantiles: `median_score`, `q25_score`, `q75_score`  
- Range: `min_score`, `max_score`
- Metadata: `total_samples`, `processing_date`, `last_updated`, `source`

## Usage for Scores Repository

These files are processed by `scripts/generate_comprehensive_stats.py` to create comprehensive statistics that are uploaded to the `evaleval/every_eval_score_ever` repository.

**Smart Indexing:** The system automatically detects existing files and creates new ones with incremental numbering (e.g., `helm-00001.parquet`, `helm-00002.parquet`). **One file per source** keeps data organized and file sizes manageable while maintaining full granular detail with one row per model-benchmark-dataset combination.
